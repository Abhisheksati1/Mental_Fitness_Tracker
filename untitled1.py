# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hPRaScqJ2ksUOlkGn8jv4buhEpMVp0oL
"""

import warnings
warnings.filterwarnings('ignore')

import numpy as np      #linear algebra
import pandas as pd     #Data processing, CSV file(e.g.pd.read_CSV)

#Mount google Drive to Google Colab

from google.colab import drive
drive.mount('/content/drive')

import seaborn as sns   #Seaborn is a python data visualization library based on matplotlib
import matplotlib.pyplot as plt    #Matplotlib is a low level graph plotting libaray in python that serves as a visualization utility
import plotly.express as px     #allows you to create interactive plots with very little code

"""Explorartory Data Analysis

Load and prepare data
"""

#prevalence-by-mental-and-substance-use-disorder.csv
df1=pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Mental Fitness/prevalence-by-mental-and-substance-use-disorder.csv")

#mental-and-substance-use-as-share-of-disease.csv
df2=pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Mental Fitness/mental-and-substance-use-as-share-of-disease.csv")

#prevalence-by-mental-and-substance-use-disorder.csv

df1.head()   #Return us top 5 records of data file

#mental-and-substance-use-as-share-of-disease.csv


df2.head(10)    #Return us top 10 records of data file

#Merging two datasets:prevalence-by-mental-and-substance-use-disorder.csv, mental-and-substance-use-as-share-of-disease.csv

data=pd.merge(df1,df2)
data.head(10)

"""Data Cleaning"""

#Missing values in the dataset

data.isnull().sum()   #To check for null values in a pandas DataFrame, isnull() function is used followed by the sum() function to return the number of null frames.

#Drop the column

data.drop('Code',axis=1,inplace=True)

#data= is the DataFrame from which you want to drop the column.
#'Code'= is the label of the column you want to remove.
#kaxis=1= specifies that you want to drop the column along the horizontal axis (columns) rather than the vertical axis (rows).
#inplace=True= is an optional parameter that indicates you want to modify the DataFrame 'data' directly, without creating a new DataFrame. When inplace=True, the original DataFrame is modified, and the operation does not return a new DataFrame.
#Therefore, by executing this code, the column 'Code' will be dropped from the 'data' DataFrame. The modified DataFrame will have all other columns except 'Code'.

#view the data

data.head(10)

# Size = row*column, Shape = tuple of array dimension(row,column)

data.size,data.shape

#The data.size attribute = returns the total number of elements in the DataFrame
 #                             which is calculated by multiplying the number of rows by the number of columns
  #  The data.shape attribute = returns a tuple that represents the dimensions of the DataFrame
   #          It provides the number of rows and columns in the DataFrame in the format (number_of_rows, number_of_columns)."""

#Column Set

#data.set_axis(['Country','Year','Schizophrenia','Bipolar_disorder','Eating_disorders','Anxiety','drug_usage','Depression','alcohol','mental_fitness'],axis='columns',inplace=True)

data.set_axis(['Country','Year','Schizophrenia','Bipolar','Eating disorders','Anxiety','Drug usage','Depression','Alcohol Usage','Mental fitness'],axis = 'columns',inplace = True)

#     Renaming column name beacuse they are too big

#View the Data

data.head(10)

"""Visualization"""

plt.figure(figsize=(12,6))
sns.heatmap(data.corr(),annot=True,cmap='Blues')    #heatmap is defined as a graphical represtation of data using colors to visualize the value of the matrix
plt.plot()

#data.corr() = calculates the correlation between columns of the DataFrame data
#annot=True = specifies that the correlation values should be displayed on the heatmap.
#cmap='Blues' = sets the color scheme for the heatmap.
#     In this case, the 'Blues' colormap is used, which represents lower values with lighter shades of blue and higher values with darker shades.

"""**Takeway Point**

  *  Eating_disorder is positively correlated to mental_fitness and vice-versa as our eating choice affect our mental health


"""

sns.pairplot(data,corner=True)   #pairwise relationships in a dataset
plt.show

mean=data['Mental fitness'].mean()
mean

fig=px.pie(data,values='Mental fitness',names='Year')
fig.show()

# Yearwise variation is mental_
fig = px.line(data, x="Year", y = "Mental fitness", color='Country',markers=True, color_discrete_sequence=['red','blue'],template='plotly_dark')
fig.show()

df = data.copy()

df.head(10)

#Information about the DataFrame

df.info()

#Transform non-numeric labels to numeric labels

from sklearn.preprocessing import LabelEncoder  #The LabelEncoder is a utility class in scikit-learn that can be used to encode categorical variables into numerical values.
l=LabelEncoder()
for i in df.columns:    #This loop iterates over the columns of the DataFrame df. For each column, it checks if the data type is 'object'
  if df[i].dtype == 'object':       #transform non-numerical labels (as long as they hashable and comparable) to numerical labels
    df[i]=l.fit_transform(df[i])    #the l.fit_transform(df[i]) method is called to fit the label encoder on the column data and transform it into encoded numerical values
                                        #The transformed values are then assigned back to the column in the DataFrame.
#The fit_transform() method of the LabelEncoder class fits the encoder on the data and transforms it in a single step. It assigns a unique numerical label to each unique category in the column, thereby converting it into numerical representation.
#Here the country are assigned numeri vlaues from 0 to infinite a unique number is given to a unique country.

df.shape

"""Split Data-(6840,10)

  * In this step, we are  going to split data in two parts(trending and testing),so that we can train our model on training dataset and test its
    accuracy on unseen data
   

"""

# x represents the features or input variables for our machine learning model.
# The df.drop('mental_fitness', axis=1) part selects all the columns from the DataFrame df except for the column named 'mental_fitness'
# x contains all the input variables (features) except the 'mental_fitness' column.
x = df.drop('Mental fitness',axis=1)
y = df['Mental fitness']   #y represents the target variable or the output we want to predict.
  # y will contain the values from the 'mental_fitness' column, which we want to predict using our machine learning model.

from sklearn.model_selection import train_test_split   #Use to split the original data into training and test data
xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=.20, random_state=2)

# The function returns four variables: xtrain (the training features), xtest (the testing features), ytrain (the training target variable), and ytest (the testing target variable).
# These variables store the corresponding subsets of data for training and testing.
# Test_size=.20 means that 20% of the total data will be assigned to the testing set, while the remaining 80% will be assigned to the training set
# random_state simply sets seed to the generator, so that your train-test split are always deterministic. If you don't set seed, it is diffrent each time

#Training (6840,10)
#6840*80/100 = 5472
#6840*20/100 = 1368

print("xtrain: ", xtrain.shape)
print("xtest: ", xtest.shape)
print("\n ytrain: ", ytrain.shape)
print("ytest: ", ytest.shape)

"""**Takeaway Points:**
  *   Usually we take more and more data in training so it's easy for the model to learn with more data

**Model Training**
  * As we done with preprocessing part. it is time to tarin our model. Iam going to use Linear Regression and Random
  Forest Regression algorithms as then we compare the performance of these two diffrent models.

---
  * **Linear Regression:**Linear regression analysis is used to predict the value of a variable based on the value of other variable. The
  variable you want to predict is called the dependent variable. The variable you are using to predict the other variable's value is called the
  independent variable.
  
  Y = AX + B
  
  Y: Dependent Varibale
  
  A: Slope
  
  X: Independent varibale
  
  B: y-intercept

  **Random Forest Regression:**A random forest is a meta estimator that fits a number of classifying decision trees on various sub-samples of
  the dataset and uses averaging to improve the predictive accuracy and control over-fitting.It is used to solve both regression and
  classification problems.
"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
lr = LinearRegression()   # Create a Linear Regression model object
lr.fit(xtrain,ytrain)    #fit training data, This trains the linear regression model on the provided data.

# model evaluation for training set
ytrain_pred = lr.predict(xtrain)  #This line uses the trained linear regression model (lr) to predict the target variable (y) for the training set (xtrain). The predicted values are stored in ytrain_pred.
# The mean sqaure error  calculates the Mean Squared Error (MSE) between the actual target values (ytrain) and the predicted target values (ytrain_pred). s
mse = mean_squared_error(ytrain, ytrain_pred)   #Observed value, predicted value

#Root Mean Square Error measures the average diffrence between values predicted by a model and the actual values
rmse = (np.sqrt(mean_squared_error(ytrain, ytrain_pred)))
#The R2 score ranges from 0 to 1, where 1 indicates a perfect fit and 0 indicates that the model does not explain the target variable at all.
#The coefficient of determinatio, or R2, is a measure that provides information about the goodness of it of a model. In the context of regression it is a statistical measure of
r2 = r2_score(ytrain, ytrain_pred)
#The R2 score ranges from 0 to 1, where 1 indicates a perfect fit and 0 indicates that the model does not explain the target variable at all.

print("The Linear Rgression model performance for training set ")
print("-----------------------------------------")
print("MSF is {}",format(mse))
print('AMSE is {}',format(rmse))
print('R2 score is {}',format(r2))

from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor()
rf.fit(xtrain, ytrain)

#model evaluation for training set
ytrain_pred = rf.predict(xtrain)
mse = mean_squared_error(ytrain, ytrain_pred)
rmse = (np.sqrt(mean_squared_error(ytrain, ytrain_pred)))
r2 = r2_score(ytrain, ytrain_pred)

print("The Random Forest Regressor model performance for training set")
print("------------------------------------")
print("MSE is {}",format(mse))
print('RMSE is {}',format(rmse))
print('R2 score is {}',format(r2))

"""Evaluation

  *  In this part we will compare the scores of above two models.


"""

# Linear Regression model evaluation for testing set
ytest_pred = lr.predict(xtest)   #using test data (unseen data)
mse = mean_squared_error(ytest, ytest_pred)
rmse = (np.sqrt(mean_squared_error(ytest, ytest_pred)))
r2 = r2_score(ytest, ytest_pred)

print("The Linear Regression model perforance for testing set ")
print("-----------------------------------")
print('MSE is {}',format(mse))
print('RMSE is {}',format(rmse))
print('R2 score is {}',format(r2))

# Random Forest Regressor model Evaluation for testing set
ytest_pred = rf.predict(xtest)
mse = mean_squared_error(ytest,ytest_pred)
rmse = (np.sqrt(mean_squared_error(ytest, ytest_pred)))
r2 = r2_score(ytest, ytest_pred)

print("The Linear Regression model performance for testing set ")
print("-----------------------------------")
print('MSE is {}',format(mse))
print('RMSE is {}',format(rmse))
print('R2 score is {}',format(r2))

"""**Takeaway Points:**
  
  * Random Forest model performs well on both training and testing data

**INPUT**
"""

print("Welcome to the Mental fitness Tracker ")
country = input("Enter the country: ")
year = int(input("Enter the year: "))
schizophrenia = float(input("Enter the rate of schizophrenia: "))
bipolar = float(input("Enter the rate of bipolar: "))
eating_disorders = float(input("Enter the rate of eating disorders: "))
anxiety = float(input("Enter the rate of anxiety: "))
drug_usage = float(input("Enter the rate of drug usage per year: "))
depression = float(input("Enter the rate of depression: "))
alcohol_usage = float(input("Enter the rate of alcohol usage: "))

"""**TRAINING MODEL**"""

X = data[['Schizophrenia', 'Bipolar', 'Eating disorders', 'Anxiety', 'Drug usage', 'Depression', 'Alcohol Usage']]
Y = data['Mental fitness']

rf.fit(X, Y)
user_input = pd.DataFrame([[schizophrenia, bipolar, eating_disorders, anxiety, drug_usage, depression, alcohol_usage]],columns=['Schizophrenia', 'Bipolar', 'Eating disorders', 'Anxiety', 'Drug usage', 'Depression', 'Alcohol Usage'])

"""**PREDICTION**"""

random_forest_prediction = rf.predict(user_input)[0]

"""**OUTPUT AND RESULT**"""

normalized_prediction = (random_forest_prediction / data['Mental fitness'].max()) * 100
print("Mental Fitness is %.2f"%(normalized_prediction))
if normalized_prediction > 80:
  print("You have a Good health condition!")
else:
  print("Improve your health condition!")
bar = 0.5
plt.bar(['Predicted Mental Fitness'], [normalized_prediction],width = bar)
plt.ylim(0, 100)
plt.xlabel('Prediction')
plt.ylabel('Mental Fitness')
plt.title('Predicted Mental Fitness')
plt.show()